

### Производная, градиент, частная производная

1. Что такое производная функции одной переменной?
    - ответ
2. Что такое частная производная?
    - ответ
3. Что такое градиент?
    - ответ
5. Посчитай градиент функции f(x1, x2) = x1^2 + x1*x2
    - ответ

### Градиентный спуск

1. Почему шаг делается «в сторону, противоположную градиенту»?
    - ответ
2. Что влияент на скорость сходимости?
    - ответ

### Batch vs Mini-batch

1. Что такое Батч в задачах ML?
    - ответ
2. На что влияет размер батча?
    - ответ
3. Какие преимущества/недостатки Batch gradient descent, mini-batch gradient descent и stohactic gradient descent?
    - ответ

### Loss-function

1. Что такое Loss-function?
    - ответ
2. Какие Loss-function берут для бинарной классификации, многоклассовой классификации, регрессии?
    - ответ

### Backpropagation

1. Кратко опиши алгоритм обратного распространения ошибок.
    - ответ
2. Что хранит PyTorch в .grad после backward()?
    - ответ

### Activation functions

1. Назови 3 популярные функции активации и их плюсы/минусы.
    - ответ

### Optimizers

1. В чём принципиальная разница между SGD и Adam?
    - ответ

### Batch Normalization

1. Что нормализуется в BatchNorm?
    - ответ
2. Как это влияет на градиенты?
    - ответ

### Dropout

1. Почему Dropout уменьшает переобучение?
    - ответ
2. Что происходит на инференсе со слоем Dropout?
    - ответ

### Gradient Accumulation

1. В каких случаях это необходимо?
    - ответ

### Early Stopping

1. Для чего нужна ранняя остановка обучения?
    - ответ
2. Какие два критерия обычно используются для остановки?
    - ответ

### Regularization L1/L2

1. Что это?
    - ответ
